ğŸ©º **MedicBotAI â€“ Detailed Project Explanation**
ğŸ™ï¸ **Frontend (Client-Side)**
The frontend handles everything the user sees and interacts with.

ğŸŒ** Language Selection**
Users can select their preferred language for speech input using a dropdown.

The chatbot updates its speech recognition model dynamically based on this choice.

ğŸ¤ **Capturing Voice Input**
Uses the Web Speech API to listen to the userâ€™s speech.

Automatically adapts to the selected language.

ğŸ›ï¸ **Mic Button Control**
Start recognition when the user clicks the mic button.

Stop recognition when the user stops speaking or clicks again.

ğŸ”— **Sending Data to Backend**
The function sendSymptomsToBackend() sends the text version of the userâ€™s symptoms to the backend server.

The backend processes the symptoms and returns an AI-generated response.

ğŸ”Š **Text-to-Speech (TTS) Output**
Converts the botâ€™s text replies into spoken audio.

Can be triggered automatically after the bot replies or manually via a speaker icon.

ğŸ‘‹ **Greeting the User**
On load, the chatbot greets the user with a TTS welcome message.

ğŸ–¥ï¸ **Backend (Server-Side)**
The backend is the brain of the application, processing input and generating intelligent responses.

ğŸ“¦ **Importing Flask & Gemini API**
Flask runs the backend server.

Google Gemini API is used to generate AI-based responses.

âš™ï¸ **App Initialization**
Flask app is set up.

Gemini API is configured using a secure API key.

ğŸ’¬ **Calling the Gemini API**
Userâ€™s symptom text is sent as a prompt to Gemini.

Gemini returns a structured AI response.

The response is parsed from raw text into usable JSON and sent back to the frontend.

ğŸš¨ **Error Handling**
If thereâ€™s an error in the code or the Gemini API fails, the system sends an error message back to the user.

ğŸ“Œ **Summary**
MedicBotAI:

ğŸ§ Listens to your voice.

ğŸ“ Understands your symptoms.

ğŸ§  Processes them using AI (Gemini API).

ğŸ’¬ Responds in text.

ğŸ”Š Speaks the reply back to you.


**THANKS FOR READING**

